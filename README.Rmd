---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# gdalcli: An R Frontend for the GDAL (>=3.11) Unified CLI

[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html)

An R interface to GDAL's unified command-line interface (GDAL >=3.11). Provides a lazy evaluation framework for building and executing GDAL commands with composable, pipe-aware functions. Supports native GDAL pipelines, GDALG format persistence, and pipeline composition.

## Installation

### Version-Specific Releases

`gdalcli` is released as version-specific builds tied to particular GDAL releases. Using a package version matching your GDAL version is recommended. Newer package versions introduce features that require newer GDAL versions. Existing functionality should generally remain compatible with older GDAL installations, though this cannot be guaranteed until the GDAL CLI is stabilized.

**See [GitHub Releases](https://github.com/brownag/gdalcli/releases) for the latest version-specific builds.**

Each release is tagged with both the package version and the GDAL version it targets:

- `v0.2.1-3.11.0` - Compatible with GDAL 3.11.0
- `v0.2.1-3.12.0` - Compatible with GDAL 3.12.0
- etc.

#### Finding Your GDAL Version

```r
# Check your system GDAL installation
system2("gdalinfo", "--version")
```

#### Installation from Release Branch

Install the version compatible with your GDAL installation:

```r
# For GDAL 3.12.x
remotes::install_github("brownag/gdalcli", ref = "release/gdal-3.12")

# For GDAL 3.11.x
remotes::install_github("brownag/gdalcli", ref = "release/gdal-3.11")
```

**Docker**: Pre-built images available at `ghcr.io/brownag/gdalcli:gdal-X.Y.Z-latest`

### Requirements

- **R** >= 4.1
- **GDAL** >= 3.11 (CLI must be available in system PATH for processx backend)
- **gdalraster** (optional; enables gdalraster backend)
- **reticulate** (optional; enables reticulate backend)

## Examples

### Basic Usage

```{r}
library(gdalcli)

# Create a job (lazy evaluation - nothing executes yet)
job <- gdal_raster_convert(
  input = system.file("extdata/sample_clay_content.tif", package = "gdalcli"),
  output = tempfile(fileext = ".tif"),
  output_format = "COG"
)

# Execute the job
gdal_job_run(job)
```

### Adding Options

```{r}
job <- gdal_raster_convert(
  input = system.file("extdata/sample_clay_content.tif", package = "gdalcli"),
  output = tempfile(fileext = ".tif"),
  output_format = "COG"
) |>
  gdal_with_co("COMPRESS=LZW", "PREDICTOR=2") |>
  gdal_with_config("GDAL_CACHEMAX=512")

gdal_job_run(job)
```

### Multi-Step Pipelines

```{r}
pipeline <- gdal_raster_reproject(
  input = system.file("extdata/sample_clay_content.tif", package = "gdalcli"),
  dst_crs = "EPSG:32632"
) |>
  gdal_raster_scale(src_min = 0, src_max = 100, dst_min = 0, dst_max = 255) |>
  gdal_raster_convert(output = tempfile(fileext = ".tif"), output_format = "COG")

gdal_job_run(pipeline)
```

### Pipeline Persistence

```{r}
# Save pipeline to GDALG format
workflow_file <- tempfile(fileext = ".gdalg.json")
gdal_save_pipeline(pipeline, workflow_file)

# Load pipeline for later use
loaded <- gdal_load_pipeline(workflow_file)
# Note: Loaded pipelines may require command type corrections for full compatibility
```

### Cloud Storage

```{r, eval=FALSE}
# Set AWS credentials (from environment variables)
auth <- gdal_auth_s3()

job <- gdal_raster_convert(
  input = "/vsis3/my-bucket/input.tif",
  output = "/vsis3/my-bucket/output.tif",
  output_format = "COG"
) |>
  gdal_with_env(auth)

gdal_job_run(job)
```

### Raster Information

```{r}
# Get detailed information about a raster file
info_job <- gdal_raster_info(
  input = system.file("extdata/sample_clay_content.tif", package = "gdalcli")
)
gdal_job_run(info_job)
```

### Vector Operations

```{r}
# Convert vector format
vector_job <- gdal_vector_convert(
  input = system.file("extdata/sample_mapunit_polygons.gpkg", package = "gdalcli"),
  output = tempfile(fileext = ".geojson"),
  output_format = "GeoJSON"
)
gdal_job_run(vector_job, backend = "processx")
```

### Raster Processing Pipeline

```{r, eval=FALSE}
# Simple processing pipeline: reproject and convert
processing_pipeline <- gdal_raster_reproject(
  input = system.file("extdata/sample_clay_content.tif", package = "gdalcli"),
  dst_crs = "EPSG:32632"
) |>
  gdal_raster_convert(output = tempfile(fileext = ".tif"))

gdal_job_run(processing_pipeline, backend = "processx")
```

## Backends

`gdalcli` supports multiple execution backends:

- **processx** (default): Executes GDAL CLI commands as subprocesses
- **gdalraster** (optional): Uses C++ GDAL bindings via gdalraster package
- **reticulate** (optional): Uses Python GDAL bindings via reticulate

Set your preferred backend globally:

```r
options(gdalcli.prefer_backend = "gdalraster")  # or "processx", "reticulate"
```

## Pipeline Features

### Native GDAL Pipeline Execution

Execute multi-step workflows as a single GDAL pipeline:

```{r, eval=FALSE}
pipeline <- gdal_raster_reproject(
  input = system.file("extdata/sample_clay_content.tif", package = "gdalcli"),
  dst_crs = "EPSG:32632"
) |>
  gdal_raster_convert(output = tempfile(fileext = ".tif"))

gdal_job_run(pipeline, backend = "processx")
```

### GDALG Format: Save and Load Pipelines

Persist pipelines as JSON for sharing and version control:

```{r}
# Save pipeline to GDALG format
workflow_file <- tempfile(fileext = ".gdalg.json")
gdal_save_pipeline(pipeline, workflow_file)

# Load pipeline for later use
loaded <- gdal_load_pipeline(workflow_file)
# Note: Loaded pipelines may require command type corrections for full compatibility
```

### Shell Script Generation

Generate executable shell scripts from pipelines:

```{r}
# Generate bash script
script <- render_shell_script(pipeline, format = "native", shell = "bash")
cat(script)
```

## Architecture

`gdalcli` uses a three-layer architecture:

1. **Frontend Layer**: Auto-generated R functions with composable modifiers
2. **Pipeline Layer**: Automatic pipeline building and GDALG serialization  
3. **Engine Layer**: Command execution with multiple backend options

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## License

MIT License - see LICENSE file for details
