# ===================================================================
# This file is AUTO-GENERATED by build/generate_gdal_api.R
# Do not edit directly. Changes will be overwritten on regeneration.
# Generated for GDAL 3.12.0
# Generation date: 2025-12-14
# ===================================================================

#' @title partition: Partition a vector dataset into multiple files
#' @description
#' Partition a vector dataset into multiple files.
#' 
#' See \url{https://gdal.org/en/3.12.0/programs/gdal_vector_partition.html} for detailed GDAL documentation.
#' @param input Input vector datasets (required). Exactly `1` value(s). Can also be a [gdal_job] object to extend a pipeline
#' @param input_format Input formats (Character vector). `0` to `2147483647` value(s) (Advanced)
#' @param output Output directory (required)
#' @param output_format Output format
#' @param field Field(s) on which to partition (Character vector) (required). `0` to `2147483647` value(s)
#' @param open_option Open options (Character vector). Format: `<KEY>=<VALUE>`. `0` to `2147483647` value(s) (Advanced)
#' @param overwrite Whether overwriting existing output is allowed (Logical) (Default: `false`)
#' @param append Whether appending to existing layer is allowed (Logical) (Default: `false`)
#' @param creation_option Creation option (Character vector). Format: `<KEY>=<VALUE>`. `0` to `2147483647` value(s)
#' @param layer_creation_option Layer creation option (Character vector). Format: `<KEY>=<VALUE>`. `0` to `2147483647` value(s)
#' @param scheme Partitioning scheme. Choices: hive, flat (Default: `hive`)
#' @param pattern Filename pattern ('part_%010d' for scheme=hive, '\{LAYER_NAME\}_\{FIELD_VALUE\}_%010d' for scheme=flat)
#' @param feature_limit Maximum number of features per file (Integer). Minimum: `0`
#' @param max_file_size Maximum file size (MB or GB suffix can be used)
#' @param omit_partitioned_field Whether to omit partitioned fields from target layer definition (Logical)
#' @param skip_errors Skip errors when writing features (Logical)
#' @return A [gdal_job] object.
#' @family gdal_vector_utilities
#' @examples

#' job <- gdal_vector_partition(input = "world_cities.gpkg", output = "out_directory", 
#'     field = "continent,country", output_format = "Parquet")
#' \dontrun{
#'   result <- gdal_job_run(job)
#' }
#' @export
gdal_vector_partition <- function(input,
  input_format = NULL,
  output,
  output_format = NULL,
  field,
  open_option = NULL,
  overwrite = FALSE,
  append = FALSE,
  creation_option = NULL,
  layer_creation_option = NULL,
  scheme = NULL,
  pattern = NULL,
  feature_limit = NULL,
  max_file_size = NULL,
  omit_partitioned_field = FALSE,
  skip_errors = FALSE) {
  new_args <- list()
  if (!missing(input)) new_args[["input"]] <- input
  if (!missing(input_format)) new_args[["input_format"]] <- input_format
  if (!missing(output)) new_args[["output"]] <- output
  if (!missing(output_format)) new_args[["output_format"]] <- output_format
  if (!missing(field)) new_args[["field"]] <- field
  if (!missing(open_option)) new_args[["open_option"]] <- open_option
  if (!missing(overwrite)) new_args[["overwrite"]] <- overwrite
  if (!missing(append)) new_args[["append"]] <- append
  if (!missing(creation_option)) new_args[["creation_option"]] <- creation_option
  if (!missing(layer_creation_option)) new_args[["layer_creation_option"]] <- layer_creation_option
  if (!missing(scheme)) new_args[["scheme"]] <- scheme
  if (!missing(pattern)) new_args[["pattern"]] <- pattern
  if (!missing(feature_limit)) new_args[["feature_limit"]] <- feature_limit
  if (!missing(max_file_size)) new_args[["max_file_size"]] <- max_file_size
  if (!missing(omit_partitioned_field)) new_args[["omit_partitioned_field"]] <- omit_partitioned_field
  if (!missing(skip_errors)) new_args[["skip_errors"]] <- skip_errors

  # Check if first argument is a piped gdal_job or actual data
  if (!missing(input) && inherits(input, 'gdal_job')) {
    # First argument is a piped job - extend the pipeline
    # Remove first_arg from new_args since it's the job, not data
    piped_job <- input
    new_args[["input"]] <- NULL
    new_args <- Filter(Negate(is.null), new_args)
    return(extend_gdal_pipeline(piped_job, c("vector", "partition"), new_args))
  }

  # First argument is actual data or missing - create new job
  merged_args <- new_args

  .arg_mapping <- list(
    input = list(min_count = 1, max_count = 1),
    input_format = list(min_count = 0, max_count = 2147483647),
    output = list(min_count = 0, max_count = 1),
    output_format = list(min_count = 0, max_count = 1),
    field = list(min_count = 0, max_count = 2147483647),
    open_option = list(min_count = 0, max_count = 2147483647),
    overwrite = list(min_count = 0, max_count = 1),
    append = list(min_count = 0, max_count = 1),
    creation_option = list(min_count = 0, max_count = 2147483647),
    layer_creation_option = list(min_count = 0, max_count = 2147483647),
    scheme = list(min_count = 0, max_count = 1),
    pattern = list(min_count = 0, max_count = 1),
    feature_limit = list(min_count = 0, max_count = 1),
    max_file_size = list(min_count = 0, max_count = 1),
    omit_partitioned_field = list(min_count = 0, max_count = 1),
    skip_errors = list(min_count = 0, max_count = 1)
  )

  new_gdal_job(command_path = c("vector", "partition"), arguments = merged_args, arg_mapping = .arg_mapping)
}

