# ===================================================================
# This file is AUTO-GENERATED by build/generate_gdal_api.R
# Do not edit directly. Changes will be overwritten on regeneration.
# ===================================================================

#' @title info: Return information on a vector dataset
#' @description
#' `gdal vector info` lists various information about a GDAL supported
#' vector dataset.
#' 
#' See \url{https://gdal.org/en/stable/programs/gdal_vector_info.html} for detailed GDAL documentation.
#' @param input Input vector dataset (Dataset path) (required). Can also be a [gdal_job] object to extend a pipeline
#' @param input_format Input formats (Character vector). `0` to `2147483647` value(s) (Advanced)
#' @param output_format Output format. Choices: json, text (Default: `json`)
#' @param open_option Open options (Character vector). Format: `<KEY>=<VALUE>`. `0` to `2147483647` value(s) (Advanced)
#' @param layer Layer name (Character vector). `0` to `2147483647` value(s)
#' @param features List all features (beware of RAM consumption on large layers) (Logical)
#' @param sql Execute the indicated SQL statement and return the result. Format: `<statement>|@<filename>`
#' @param where Attribute query in a restricted form of the queries used in the SQL WHERE statement. Format: `<WHERE>|@<filename>`
#' @param dialect SQL dialect
#' @param update Open the dataset in update mode (Logical)
#' @param stdout Directly output on stdout (format=text mode only). If enabled, output-string will be empty (Logical)
#' @return A [gdal_job] object.
#' @family gdal_vector_utilities
#' @examples
#' # Example
#' # gdal vector info --format=text --features poly.gpkg
#' job <- gdal_vector_info(features = "poly.gpkg")
#' @export
gdal_vector_info <- function(input,
  input_format = NULL,
  output_format = NULL,
  open_option = NULL,
  layer = NULL,
  features = FALSE,
  sql = NULL,
  where = NULL,
  dialect = NULL,
  update = FALSE,
  stdout = FALSE) {
  new_args <- list()
  if (!missing(input)) new_args[["input"]] <- input
  if (!missing(input_format)) new_args[["input_format"]] <- input_format
  if (!missing(output_format)) new_args[["output_format"]] <- output_format
  if (!missing(open_option)) new_args[["open_option"]] <- open_option
  if (!missing(layer)) new_args[["layer"]] <- layer
  if (!missing(features)) new_args[["features"]] <- features
  if (!missing(sql)) new_args[["sql"]] <- sql
  if (!missing(where)) new_args[["where"]] <- where
  if (!missing(dialect)) new_args[["dialect"]] <- dialect
  if (!missing(update)) new_args[["update"]] <- update
  if (!missing(stdout)) new_args[["stdout"]] <- stdout

  # Check if first argument is a piped gdal_job or actual data
  if (!missing(input) && inherits(input, 'gdal_job')) {
    # First argument is a piped job - extend the pipeline
    # Remove first_arg from new_args since it's the job, not data
    piped_job <- input
    new_args[["input"]] <- NULL
    new_args <- Filter(Negate(is.null), new_args)
    return(extend_gdal_pipeline(piped_job, c("vector", "info"), new_args))
  }

  # First argument is actual data or missing - create new job
  merged_args <- new_args

  .arg_mapping <- list(
    input = list(min_count = 0, max_count = 1),
    input_format = list(min_count = 0, max_count = 2147483647),
    output_format = list(min_count = 0, max_count = 1),
    open_option = list(min_count = 0, max_count = 2147483647),
    layer = list(min_count = 0, max_count = 2147483647),
    features = list(min_count = 0, max_count = 1),
    sql = list(min_count = 0, max_count = 1),
    where = list(min_count = 0, max_count = 1),
    dialect = list(min_count = 0, max_count = 1),
    update = list(min_count = 0, max_count = 1),
    stdout = list(min_count = 0, max_count = 1)
  )

  new_gdal_job(command_path = c("vector", "info"), arguments = merged_args, arg_mapping = .arg_mapping)
}

